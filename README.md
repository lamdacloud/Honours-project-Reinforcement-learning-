This repository contains the implementations of using reinforcement learning and co-evolution to create an agent that learns the game of backgammon.
This project was inspired from the success of researcher, Gerald Tesauro, who had successfully been able to create an AI player that learned through self play, and was
able to rival the best of players in the game of backgammon back in the year 1992. The RL (reinforcement learning) algorithm used 
is gradient descent TD($\lambda$) and another implementation was made using co-evolution where our agent "evolves" and learns to play the game by playing
with a mutant copy of itself. 

Important Resources:
* Gerald Tesauro. “Temporal Difference Learning and TD-Gammon”. In: Communications of
the ACM/Association for Computing Machinery 38.3 (1995).

* Jordan B. Pollack and Alan D. Blair. “Why did TD-Gammon Work?”

* Jenna Carr. “An Introduction to Genetic Algorithms”.

* Gerald Tesauro. “Practical Issues in Temporal Difference Learning”. In: Mach Learn 8, 257–277
(1992). (). doi: https://doi.org/10.1007/BF00992697

* Richard S. Sutton and Andrew G. Barto. Reinforcement Learning: An Introduction (2nd edition).
The MIT Press Cambridge, Massachusetts London, England, 2014, 2015, p
